{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3l0sCSZxR2I",
        "outputId": "8c742895-2e32-4ea5-9f91-7117ed3b6543"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ru-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-sm==3.7.0) (3.7.5)\n",
            "Collecting pymorphy3>=1.0.0 (from ru-core-news-sm==3.7.0)\n",
            "  Downloading pymorphy3-2.0.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m970.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: pymorphy3-dicts-ru, dawg-python, pymorphy3, ru-core-news-sm\n",
            "Successfully installed dawg-python-0.7.2 pymorphy3-2.0.1 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nj5UAwiSnO-e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# загрузка библиотеки spacy и русского словаря\n",
        "import spacy\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "\n",
        "import ru_core_news_sm\n",
        "nlp = ru_core_news_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwIl80QVtYBG",
        "outputId": "515dda11-b331-4979-a228-cb6209d6d914"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# указываем путь к рабочей папке\n",
        "path = '/content/drive/MyDrive/hack_lct24'\n",
        "\n",
        "# указываем имя файла с тестовым датасетом\n",
        "test_filename = 'gt_test.csv'"
      ],
      "metadata": {
        "id": "dtSD7sc_tZ6-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "km8si48k3nwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вспомогательная функция для определение номера токена в выборке по номеру его позиции\n",
        "def find_pos(parser_array, n):\n",
        "    pos = -1\n",
        "    if n != -1:\n",
        "        i = 0\n",
        "        while i < len(parser_array):\n",
        "            if parser_array[i]['pos'] == n:\n",
        "                pos = i\n",
        "                break\n",
        "            i += 1\n",
        "    return pos\n",
        "\n",
        "# вспомогательная функция для корректировки отношения токена\n",
        "def correct_relation(parser_array, n):\n",
        "    i = find_pos(parser_array, n)\n",
        "    if i != -1:\n",
        "        if parser_array[i]['code'] == 'value':\n",
        "            if parser_array[i]['relation'] != parser_array[i]['pos']:\n",
        "                rel = correct_relation(parser_array, parser_array[i]['relation'])\n",
        "                parser_array[i]['relation'] = rel\n",
        "            else:\n",
        "                rel = parser_array[i]['pos']\n",
        "        else:\n",
        "            rel = parser_array[i]['pos']\n",
        "    else:\n",
        "        rel = n\n",
        "\n",
        "    return rel\n",
        "\n",
        "\n",
        "# функция для поиска в заданном тексте интересующих слов\n",
        "# (\"скидка\", числа, относящиеся к скидке, а также единицу измерения скидки: \"процент\" или \"рубль\")\n",
        "def parser_text(inp_text):\n",
        "    '''\n",
        "    вход:\n",
        "    inp_text - строка с входным текстом, в котором нуждной найти заданные слова\n",
        "\n",
        "    выход:\n",
        "    out_array - массив с маркерами, размерность которого равна кол-ву слов во входном тексте\n",
        "\n",
        "    '''\n",
        "\n",
        "    # обработаем входной текст с помощью spacy\n",
        "    doc = nlp(inp_text)\n",
        "\n",
        "    # запишем в inp_text_parser интересующие нас токены\n",
        "    inp_text_parser = []\n",
        "    for i in range(len(doc)):\n",
        "        if doc[i].lemma_ in ['скидка', 'взнос', 'стоимость', 'цена', 'оплата', 'предоплата', 'ставка', 'ипотека', 'кредит']:\n",
        "            # анализируемые сущности\n",
        "            inp_text_parser += [{'pos': i, 'text': doc[i].text, 'lemma': doc[i].lemma_, 'code': 'entity'}]\n",
        "        elif doc[i].lemma_ in ['процент', 'рубль', 'метр', 'квадрат', 'год', 'квартал', 'неделя', 'месяц', 'день', 'условие', 'этаж', 'корпус']:\n",
        "            # измерения для чисел\n",
        "            inp_text_parser += [{'pos': i, 'text': doc[i].text, 'lemma': doc[i].lemma_, 'code': 'measure', 'relation': -1}]\n",
        "        elif doc[i].like_num:\n",
        "            # числа\n",
        "            inp_text_parser += [{'pos': i, 'text': doc[i].text, 'lemma': doc[i].lemma_, 'code': 'value', 'relation': doc[i].head.i}]\n",
        "\n",
        "    # корректируем для чисел их отношение к измерению\n",
        "    for i in range(len(inp_text_parser)):\n",
        "        if inp_text_parser[i]['code'] == 'value':\n",
        "            _ = correct_relation(inp_text_parser, inp_text_parser[i]['pos'])\n",
        "\n",
        "    # удалим токены-числа и токены-измерения, если они относятся не к измерениям \"процент\" или \"рубль\"\n",
        "    length_parser = len(inp_text_parser)\n",
        "    i = 0\n",
        "    while i < length_parser:\n",
        "        if inp_text_parser[i]['code'] == 'value':\n",
        "            j = find_pos(inp_text_parser, inp_text_parser[i]['relation'])\n",
        "            if (j == -1) or not(inp_text_parser[j]['lemma'] in ['процент', 'рубль']):\n",
        "                _ = inp_text_parser.pop(i)\n",
        "                length_parser -= 1\n",
        "            else:\n",
        "                i += 1\n",
        "        elif (inp_text_parser[i]['code'] == 'measure') and not(inp_text_parser[i]['lemma'] in ['процент', 'рубль']):\n",
        "            _ = inp_text_parser.pop(i)\n",
        "            length_parser -= 1\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    # расчитаем расстояния между сущностями и началом блоков чисел и измерения слева и справа\n",
        "    # если между сущностями отсутствуют ичла и измерения, то установим -1\n",
        "    length_parser = len(inp_text_parser)\n",
        "    for i in range(length_parser):\n",
        "        if inp_text_parser[i]['code'] == 'entity':\n",
        "            left = -1\n",
        "            if (i-1 >= 0) and (inp_text_parser[i-1]['code'] in ['value', 'measure']):\n",
        "                left = abs(inp_text_parser[i]['pos'] - inp_text_parser[i-1]['pos'])\n",
        "            inp_text_parser[i]['left'] = left\n",
        "            right = -1\n",
        "            if (i+1 < length_parser) and (inp_text_parser[i+1]['code'] in ['value', 'measure']):\n",
        "                right = abs(inp_text_parser[i]['pos'] - inp_text_parser[i+1]['pos'])\n",
        "            inp_text_parser[i]['right'] = right\n",
        "\n",
        "    # удалим сущности для которых растояния и слева и справа -1\n",
        "    length_parser = len(inp_text_parser)\n",
        "    i = 0\n",
        "    while i < length_parser:\n",
        "        if (inp_text_parser[i]['code'] == 'entity') and (inp_text_parser[i]['left'] == -1) and (inp_text_parser[i]['right'] == -1):\n",
        "            _ = inp_text_parser.pop(i)\n",
        "            length_parser -= 1\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    # установим для чисел и измерений их отношение к сущностям\n",
        "    length_parser = len(inp_text_parser)\n",
        "    for i in range(length_parser):\n",
        "        if inp_text_parser[i]['code'] == 'entity':\n",
        "            if (inp_text_parser[i]['left'] == -1) or ((inp_text_parser[i]['left'] >= inp_text_parser[i]['right']) and (inp_text_parser[i]['right'] != -1)):\n",
        "                j = i+1\n",
        "                while (j < length_parser) and (inp_text_parser[j]['code'] != 'entity'):\n",
        "                    j += 1\n",
        "                if (i != j) and (j < length_parser) and (inp_text_parser[j]['code'] == 'entity') and (inp_text_parser[i]['right'] < inp_text_parser[j]['left']):\n",
        "                    pos = inp_text_parser[i]['pos']\n",
        "                    for k in range(i, j+1):\n",
        "                        inp_text_parser[k]['relation'] = pos\n",
        "                        inp_text_parser[k]['marker'] = 'I-value'\n",
        "                    inp_text_parser[i+1]['marker'] = 'B-value'\n",
        "            elif (inp_text_parser[i]['right'] == -1) or ((inp_text_parser[i]['left'] < inp_text_parser[i]['right']) and (inp_text_parser[i]['left'] != -1)):\n",
        "                j = i-1\n",
        "                while (j > 0) and (inp_text_parser[j]['code'] != 'entity'):\n",
        "                    j -= 1\n",
        "                if (i != j) and (j > 0) and (inp_text_parser[j]['code'] == 'entity') and (inp_text_parser[i]['left'] < inp_text_parser[j]['right']):\n",
        "                    pos = inp_text_parser[i]['pos']\n",
        "                    for k in range(j, i):\n",
        "                        inp_text_parser[k]['relation'] = pos\n",
        "                        inp_text_parser[k]['marker'] = 'I-value'\n",
        "                    inp_text_parser[j+1]['marker'] = 'B-value'\n",
        "\n",
        "    # удалим токены-числа и токены-измерения, если они относятся не к сущности \"скидка\"\n",
        "    length_parser = len(inp_text_parser)\n",
        "    i = 0\n",
        "    while i < length_parser:\n",
        "        if inp_text_parser[i]['code'] in ['value', 'measure']:\n",
        "            j = find_pos(inp_text_parser, inp_text_parser[i]['relation'])\n",
        "            if (j == -1) or not(inp_text_parser[j]['lemma'] in ['скидка']):\n",
        "                _ = inp_text_parser.pop(i)\n",
        "                length_parser -= 1\n",
        "            else:\n",
        "                i += 1\n",
        "        elif inp_text_parser[i]['code'] == 'entity':\n",
        "            if inp_text_parser[i]['lemma'] in ['скидка']:\n",
        "                inp_text_parser[i]['marker'] = 'B-discount'\n",
        "                i += 1\n",
        "            else:\n",
        "                _ = inp_text_parser.pop(i)\n",
        "                length_parser -= 1\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    # сформируем выходной массив\n",
        "    out_array = ['O' for i in range(len(doc))]\n",
        "\n",
        "    # расставим в выходном массиве маркеры для найденных слов\n",
        "    for i in range(length_parser):\n",
        "        pos = inp_text_parser[i]['pos']\n",
        "        out_array[pos] = inp_text_parser[i]['marker']\n",
        "\n",
        "    return out_array"
      ],
      "metadata": {
        "id": "qUYc8cY1M8dR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZPB_3ExmywE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем тестовый датасет по указанному пути\n",
        "df_test = pd.read_csv(os.path.join(path, test_filename))"
      ],
      "metadata": {
        "id": "IekqUEDcVLYD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выделим тестовые фразы в отдельный массив\n",
        "test_texts = df_test['processed_text'].tolist()"
      ],
      "metadata": {
        "id": "iSm-K6RFCNJS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выполним parser_text для каждой тестовой фразы\n",
        "# сохраняя результат обработки в выходной массив\n",
        "test_arr = []\n",
        "for test_txt in tqdm(test_texts):\n",
        "    test_arr += [parser_text(test_txt)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MemgHuR2CNGa",
        "outputId": "a0b9f4e6-4b14-498c-ae4e-d2a41c5f25b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 482/482 [01:01<00:00,  7.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# обновим поле с метками в тестовом датасете\n",
        "df_test['label'] = test_arr"
      ],
      "metadata": {
        "id": "kBr1JNIT3FE5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраним датасет в submission.csv по указанному пути\n",
        "df_test.to_csv(os.path.join(path, 'submission.csv'), index=False)"
      ],
      "metadata": {
        "id": "5P23NaETC23K"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}